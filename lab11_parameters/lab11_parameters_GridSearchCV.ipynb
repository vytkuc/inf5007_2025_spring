{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yhK5dPfkmHKB"
      },
      "outputs": [],
      "source": [
        "#https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "J2iBh7JImHKC"
      },
      "outputs": [],
      "source": [
        "datafile = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikeras"
      ],
      "metadata": {
        "id": "4Lg1iLaSoGvO",
        "outputId": "1816ca37-628f-4750-a24b-c58235aa8244",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikeras in /usr/local/lib/python3.10/dist-packages (0.13.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from scikeras) (3.3.3)\n",
            "Requirement already satisfied: scikit-learn>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from scikeras) (1.4.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (1.25.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (3.9.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.11.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.2.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras>=3.2.0->scikeras) (4.11.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->scikeras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->scikeras) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Batch size and epochs"
      ],
      "metadata": {
        "id": "TsZalgcRmRGS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKNgkFBkmHKC",
        "outputId": "f19ae03c-5934-4822-b03d-5d6b1ccf0cd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: 0.694010 using {'batch_size': 80, 'epochs': 100}\n",
            "0.634115 (0.031948) with: {'batch_size': 10, 'epochs': 10}\n",
            "0.661458 (0.009744) with: {'batch_size': 10, 'epochs': 50}\n",
            "0.660156 (0.026107) with: {'batch_size': 10, 'epochs': 100}\n",
            "0.578125 (0.088100) with: {'batch_size': 20, 'epochs': 10}\n",
            "0.682292 (0.023073) with: {'batch_size': 20, 'epochs': 50}\n",
            "0.679688 (0.003189) with: {'batch_size': 20, 'epochs': 100}\n",
            "0.518229 (0.068875) with: {'batch_size': 40, 'epochs': 10}\n",
            "0.664062 (0.019401) with: {'batch_size': 40, 'epochs': 50}\n",
            "0.640625 (0.022097) with: {'batch_size': 40, 'epochs': 100}\n",
            "0.528646 (0.088292) with: {'batch_size': 60, 'epochs': 10}\n",
            "0.627604 (0.006639) with: {'batch_size': 60, 'epochs': 50}\n",
            "0.639323 (0.033804) with: {'batch_size': 60, 'epochs': 100}\n",
            "0.432292 (0.068579) with: {'batch_size': 80, 'epochs': 10}\n",
            "0.634115 (0.010253) with: {'batch_size': 80, 'epochs': 50}\n",
            "0.694010 (0.020505) with: {'batch_size': 80, 'epochs': 100}\n",
            "0.368490 (0.022628) with: {'batch_size': 100, 'epochs': 10}\n",
            "0.575521 (0.042112) with: {'batch_size': 100, 'epochs': 50}\n",
            "0.635417 (0.039365) with: {'batch_size': 100, 'epochs': 100}\n"
          ]
        }
      ],
      "source": [
        "# Use scikit-learn to grid search the batch size and epochs\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "\n",
        "# Function to create model, required for KerasClassifier\n",
        "def create_model():\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(12, input_shape=(8,), activation='relu'))\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\treturn model\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "# load dataset\n",
        "dataset = np.loadtxt(datafile, delimiter=\",\")\n",
        "\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "\n",
        "# create model\n",
        "model = KerasClassifier(model=create_model, verbose=0)\n",
        "\n",
        "####################################################\n",
        "# define the grid search parameters\n",
        "batch_size = [10, 20, 40, 60, 80, 100]\n",
        "epochs = [10, 50, 100]\n",
        "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
        "grid_result = grid.fit(X, Y)\n",
        "####################################################\n",
        "\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimizer"
      ],
      "metadata": {
        "id": "zVj_uRI3mT9_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TK55TOJmHKD",
        "outputId": "48e15644-da9e-4a21-9d72-8a1a1836d931"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: 0.703125 using {'optimizer': 'SGD'}\n",
            "0.703125 (0.048159) with: {'optimizer': 'SGD'}\n",
            "0.618490 (0.020752) with: {'optimizer': 'RMSprop'}\n",
            "0.591146 (0.039879) with: {'optimizer': 'Adagrad'}\n",
            "0.488281 (0.090941) with: {'optimizer': 'Adadelta'}\n",
            "0.670573 (0.049445) with: {'optimizer': 'Adam'}\n",
            "0.664062 (0.022326) with: {'optimizer': 'Adamax'}\n",
            "0.692708 (0.015073) with: {'optimizer': 'Nadam'}\n"
          ]
        }
      ],
      "source": [
        "# Use scikit-learn to grid search the optimizer\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "\n",
        "# Function to create model, required for KerasClassifier\n",
        "def create_model():\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(12, input_shape=(8,), activation='relu'))\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        "  ####################################################\n",
        "\t# return model without compile\n",
        "\treturn model\n",
        "\t####################################################\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "# load dataset\n",
        "dataset = np.loadtxt(datafile, delimiter=\",\")\n",
        "\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "\n",
        "# create model\n",
        "model = KerasClassifier(model=create_model, loss=\"binary_crossentropy\", epochs=100, batch_size=10, verbose=0)\n",
        "\n",
        "####################################################\n",
        "# define the grid search parameters\n",
        "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
        "param_grid = dict(optimizer=optimizer)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
        "grid_result = grid.fit(X, Y)\n",
        "####################################################\n",
        "\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Learning rate and momentum"
      ],
      "metadata": {
        "id": "bnSJPTcAmVtV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgIRttGzmHKE",
        "outputId": "aa357306-eb0f-413b-f9aa-ca25de2e47db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: 0.678385 using {'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.2}\n",
            "0.667969 (0.016573) with: {'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.0}\n",
            "0.678385 (0.009744) with: {'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.2}\n",
            "0.653646 (0.021236) with: {'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.4}\n",
            "0.652344 (0.012758) with: {'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.6}\n",
            "0.670573 (0.023939) with: {'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.8}\n",
            "0.656250 (0.011500) with: {'optimizer__learning_rate': 0.001, 'optimizer__momentum': 0.9}\n",
            "0.667969 (0.022999) with: {'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.0}\n",
            "0.666667 (0.025780) with: {'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.2}\n",
            "0.657552 (0.021236) with: {'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.4}\n",
            "0.645833 (0.004872) with: {'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.6}\n",
            "0.649740 (0.003683) with: {'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.8}\n",
            "0.651042 (0.001841) with: {'optimizer__learning_rate': 0.01, 'optimizer__momentum': 0.9}\n",
            "0.651042 (0.001841) with: {'optimizer__learning_rate': 0.1, 'optimizer__momentum': 0.0}\n",
            "0.651042 (0.001841) with: {'optimizer__learning_rate': 0.1, 'optimizer__momentum': 0.2}\n",
            "0.651042 (0.001841) with: {'optimizer__learning_rate': 0.1, 'optimizer__momentum': 0.4}\n",
            "0.651042 (0.001841) with: {'optimizer__learning_rate': 0.1, 'optimizer__momentum': 0.6}\n",
            "0.649740 (0.003683) with: {'optimizer__learning_rate': 0.1, 'optimizer__momentum': 0.8}\n",
            "0.651042 (0.001841) with: {'optimizer__learning_rate': 0.1, 'optimizer__momentum': 0.9}\n",
            "0.651042 (0.001841) with: {'optimizer__learning_rate': 0.2, 'optimizer__momentum': 0.0}\n",
            "0.651042 (0.001841) with: {'optimizer__learning_rate': 0.2, 'optimizer__momentum': 0.2}\n",
            "0.651042 (0.001841) with: {'optimizer__learning_rate': 0.2, 'optimizer__momentum': 0.4}\n",
            "0.651042 (0.001841) with: {'optimizer__learning_rate': 0.2, 'optimizer__momentum': 0.6}\n",
            "0.651042 (0.001841) with: {'optimizer__learning_rate': 0.2, 'optimizer__momentum': 0.8}\n",
            "0.651042 (0.001841) with: {'optimizer__learning_rate': 0.2, 'optimizer__momentum': 0.9}\n",
            "0.651042 (0.001841) with: {'optimizer__learning_rate': 0.3, 'optimizer__momentum': 0.0}\n",
            "0.649740 (0.003683) with: {'optimizer__learning_rate': 0.3, 'optimizer__momentum': 0.2}\n",
            "0.651042 (0.001841) with: {'optimizer__learning_rate': 0.3, 'optimizer__momentum': 0.4}\n",
            "0.651042 (0.001841) with: {'optimizer__learning_rate': 0.3, 'optimizer__momentum': 0.6}\n",
            "0.651042 (0.001841) with: {'optimizer__learning_rate': 0.3, 'optimizer__momentum': 0.8}\n",
            "0.651042 (0.001841) with: {'optimizer__learning_rate': 0.3, 'optimizer__momentum': 0.9}\n"
          ]
        }
      ],
      "source": [
        "# Use scikit-learn to grid search the learning rate and momentum\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "\n",
        "# Function to create model, required for KerasClassifier\n",
        "def create_model():\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(12, input_shape=(8,), activation='relu'))\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        "  ####################################################\n",
        "\treturn model\n",
        "\t####################################################\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "# load dataset\n",
        "dataset = np.loadtxt(datafile, delimiter=\",\")\n",
        "\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "\n",
        "# create model\n",
        "model = KerasClassifier(model=create_model, loss=\"binary_crossentropy\", optimizer=\"SGD\", epochs=100, batch_size=10, verbose=0)\n",
        "\n",
        "####################################################\n",
        "# define the grid search parameters\n",
        "learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
        "momentum = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9]\n",
        "param_grid = dict(optimizer__learning_rate=learn_rate, optimizer__momentum=momentum)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
        "grid_result = grid.fit(X, Y)\n",
        "####################################################\n",
        "\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Weight initialization"
      ],
      "metadata": {
        "id": "Ll46aET0maH3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghJHsCAGmHKE",
        "outputId": "9c1ebb42-fa61-49ad-d71e-f28f64913471"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: 0.713542 using {'model__init_mode': 'normal'}\n",
            "0.695312 (0.019918) with: {'model__init_mode': 'uniform'}\n",
            "0.690104 (0.027866) with: {'model__init_mode': 'lecun_uniform'}\n",
            "0.713542 (0.034401) with: {'model__init_mode': 'normal'}\n",
            "0.651042 (0.001841) with: {'model__init_mode': 'zero'}\n",
            "0.678385 (0.004872) with: {'model__init_mode': 'glorot_normal'}\n",
            "0.697917 (0.018688) with: {'model__init_mode': 'glorot_uniform'}\n",
            "0.670573 (0.014382) with: {'model__init_mode': 'he_normal'}\n",
            "0.640625 (0.046983) with: {'model__init_mode': 'he_uniform'}\n"
          ]
        }
      ],
      "source": [
        "# Use scikit-learn to grid search the weight initialization\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "\n",
        "# Function to create model, required for KerasClassifier\n",
        "def create_model(init_mode='uniform'):\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(12, input_shape=(8,), kernel_initializer=init_mode, activation='relu'))\n",
        "\tmodel.add(Dense(1, kernel_initializer=init_mode, activation='sigmoid'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\treturn model\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "# load dataset\n",
        "dataset = np.loadtxt(datafile, delimiter=\",\")\n",
        "\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "\n",
        "# create model\n",
        "model = KerasClassifier(model=create_model, epochs=100, batch_size=10, verbose=0)\n",
        "\n",
        "####################################################\n",
        "# define the grid search parameters\n",
        "init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
        "param_grid = dict(model__init_mode=init_mode)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
        "grid_result = grid.fit(X, Y)\n",
        "####################################################\n",
        "\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Activation function"
      ],
      "metadata": {
        "id": "4Rb3lzjrmd2z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8pivbiTmHKF",
        "outputId": "32805c9c-09e5-4cab-ead5-9d2f2c5f5f26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: 0.725260 using {'model__activation': 'softplus'}\n",
            "0.670573 (0.018136) with: {'model__activation': 'softmax'}\n",
            "0.725260 (0.024150) with: {'model__activation': 'softplus'}\n",
            "0.666667 (0.019225) with: {'model__activation': 'softsign'}\n",
            "0.713542 (0.015073) with: {'model__activation': 'relu'}\n",
            "0.664062 (0.033603) with: {'model__activation': 'tanh'}\n",
            "0.677083 (0.021236) with: {'model__activation': 'sigmoid'}\n",
            "0.678385 (0.007366) with: {'model__activation': 'hard_sigmoid'}\n",
            "0.710938 (0.017758) with: {'model__activation': 'linear'}\n"
          ]
        }
      ],
      "source": [
        "# Use scikit-learn to grid search the activation function\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "\n",
        "# Function to create model, required for KerasClassifier\n",
        "def create_model(activation='relu'):\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(12, input_shape=(8,), kernel_initializer='uniform', activation=activation))\n",
        "\tmodel.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\treturn model\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "# load dataset\n",
        "dataset = np.loadtxt(datafile, delimiter=\",\")\n",
        "\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "\n",
        "# create model\n",
        "model = KerasClassifier(model=create_model, epochs=100, batch_size=10, verbose=0)\n",
        "\n",
        "####################################################\n",
        "# define the grid search parameters\n",
        "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
        "param_grid = dict(model__activation=activation)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
        "grid_result = grid.fit(X, Y)\n",
        "####################################################\n",
        "\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dropout rate"
      ],
      "metadata": {
        "id": "_YyM5U0Fmf-n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4sqET5GmHKG",
        "outputId": "f762c2fb-fdb9-40a4-c8c3-065d909d1cfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "float64 (768, 9)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: 0.725260 using {'model__dropout_rate': 0.1, 'model__weight_constraint': 4.0}\n",
            "0.700521 (0.003683) with: {'model__dropout_rate': 0.0, 'model__weight_constraint': 1.0}\n",
            "0.717448 (0.010253) with: {'model__dropout_rate': 0.0, 'model__weight_constraint': 2.0}\n",
            "0.704427 (0.012890) with: {'model__dropout_rate': 0.0, 'model__weight_constraint': 3.0}\n",
            "0.690104 (0.018688) with: {'model__dropout_rate': 0.0, 'model__weight_constraint': 4.0}\n",
            "0.712240 (0.013279) with: {'model__dropout_rate': 0.0, 'model__weight_constraint': 5.0}\n",
            "0.704427 (0.004872) with: {'model__dropout_rate': 0.1, 'model__weight_constraint': 1.0}\n",
            "0.714844 (0.017758) with: {'model__dropout_rate': 0.1, 'model__weight_constraint': 2.0}\n",
            "0.720052 (0.015733) with: {'model__dropout_rate': 0.1, 'model__weight_constraint': 3.0}\n",
            "0.725260 (0.014731) with: {'model__dropout_rate': 0.1, 'model__weight_constraint': 4.0}\n",
            "0.712240 (0.012890) with: {'model__dropout_rate': 0.1, 'model__weight_constraint': 5.0}\n",
            "0.716146 (0.010253) with: {'model__dropout_rate': 0.2, 'model__weight_constraint': 1.0}\n",
            "0.710938 (0.011500) with: {'model__dropout_rate': 0.2, 'model__weight_constraint': 2.0}\n",
            "0.714844 (0.011500) with: {'model__dropout_rate': 0.2, 'model__weight_constraint': 3.0}\n",
            "0.701823 (0.008027) with: {'model__dropout_rate': 0.2, 'model__weight_constraint': 4.0}\n",
            "0.695312 (0.003189) with: {'model__dropout_rate': 0.2, 'model__weight_constraint': 5.0}\n",
            "0.712240 (0.007366) with: {'model__dropout_rate': 0.3, 'model__weight_constraint': 1.0}\n",
            "0.716146 (0.010253) with: {'model__dropout_rate': 0.3, 'model__weight_constraint': 2.0}\n",
            "0.701823 (0.011201) with: {'model__dropout_rate': 0.3, 'model__weight_constraint': 3.0}\n",
            "0.714844 (0.011500) with: {'model__dropout_rate': 0.3, 'model__weight_constraint': 4.0}\n",
            "0.694010 (0.014382) with: {'model__dropout_rate': 0.3, 'model__weight_constraint': 5.0}\n",
            "0.701823 (0.004872) with: {'model__dropout_rate': 0.4, 'model__weight_constraint': 1.0}\n",
            "0.717448 (0.006639) with: {'model__dropout_rate': 0.4, 'model__weight_constraint': 2.0}\n",
            "0.710938 (0.006379) with: {'model__dropout_rate': 0.4, 'model__weight_constraint': 3.0}\n",
            "0.705729 (0.004872) with: {'model__dropout_rate': 0.4, 'model__weight_constraint': 4.0}\n",
            "0.717448 (0.008027) with: {'model__dropout_rate': 0.4, 'model__weight_constraint': 5.0}\n",
            "0.707031 (0.020915) with: {'model__dropout_rate': 0.5, 'model__weight_constraint': 1.0}\n",
            "0.703125 (0.009568) with: {'model__dropout_rate': 0.5, 'model__weight_constraint': 2.0}\n",
            "0.704427 (0.020505) with: {'model__dropout_rate': 0.5, 'model__weight_constraint': 3.0}\n",
            "0.703125 (0.005524) with: {'model__dropout_rate': 0.5, 'model__weight_constraint': 4.0}\n",
            "0.703125 (0.008438) with: {'model__dropout_rate': 0.5, 'model__weight_constraint': 5.0}\n",
            "0.704427 (0.015733) with: {'model__dropout_rate': 0.6, 'model__weight_constraint': 1.0}\n",
            "0.696615 (0.016053) with: {'model__dropout_rate': 0.6, 'model__weight_constraint': 2.0}\n",
            "0.704427 (0.008027) with: {'model__dropout_rate': 0.6, 'model__weight_constraint': 3.0}\n",
            "0.701823 (0.009744) with: {'model__dropout_rate': 0.6, 'model__weight_constraint': 4.0}\n",
            "0.708333 (0.008027) with: {'model__dropout_rate': 0.6, 'model__weight_constraint': 5.0}\n",
            "0.700521 (0.013279) with: {'model__dropout_rate': 0.7, 'model__weight_constraint': 1.0}\n",
            "0.700521 (0.012075) with: {'model__dropout_rate': 0.7, 'model__weight_constraint': 2.0}\n",
            "0.703125 (0.011500) with: {'model__dropout_rate': 0.7, 'model__weight_constraint': 3.0}\n",
            "0.699219 (0.019918) with: {'model__dropout_rate': 0.7, 'model__weight_constraint': 4.0}\n",
            "0.688802 (0.012890) with: {'model__dropout_rate': 0.7, 'model__weight_constraint': 5.0}\n",
            "0.687500 (0.017758) with: {'model__dropout_rate': 0.8, 'model__weight_constraint': 1.0}\n",
            "0.684896 (0.009207) with: {'model__dropout_rate': 0.8, 'model__weight_constraint': 2.0}\n",
            "0.688802 (0.017566) with: {'model__dropout_rate': 0.8, 'model__weight_constraint': 3.0}\n",
            "0.694010 (0.008027) with: {'model__dropout_rate': 0.8, 'model__weight_constraint': 4.0}\n",
            "0.688802 (0.012890) with: {'model__dropout_rate': 0.8, 'model__weight_constraint': 5.0}\n",
            "0.680990 (0.001841) with: {'model__dropout_rate': 0.9, 'model__weight_constraint': 1.0}\n",
            "0.680990 (0.016053) with: {'model__dropout_rate': 0.9, 'model__weight_constraint': 2.0}\n",
            "0.667969 (0.008438) with: {'model__dropout_rate': 0.9, 'model__weight_constraint': 3.0}\n",
            "0.675781 (0.006379) with: {'model__dropout_rate': 0.9, 'model__weight_constraint': 4.0}\n",
            "0.671875 (0.014616) with: {'model__dropout_rate': 0.9, 'model__weight_constraint': 5.0}\n"
          ]
        }
      ],
      "source": [
        "# Use scikit-learn to grid search the dropout rate\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.constraints import MaxNorm\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "\n",
        "# Function to create model, required for KerasClassifier\n",
        "def create_model(dropout_rate, weight_constraint):\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(12, input_shape=(8,), kernel_initializer='uniform', activation='linear', kernel_constraint=MaxNorm(weight_constraint)))\n",
        "\tmodel.add(Dropout(dropout_rate))\n",
        "\tmodel.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\treturn model\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "# load dataset\n",
        "dataset = np.loadtxt(datafile, delimiter=\",\")\n",
        "print(dataset.dtype, dataset.shape)\n",
        "\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "\n",
        "# create model\n",
        "model = KerasClassifier(model=create_model, epochs=100, batch_size=10, verbose=0)\n",
        "\n",
        "####################################################\n",
        "# define the grid search parameters\n",
        "weight_constraint = [1.0, 2.0, 3.0, 4.0, 5.0]\n",
        "dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
        "param_grid = dict(model__dropout_rate=dropout_rate, model__weight_constraint=weight_constraint)\n",
        "#param_grid = dict(model__dropout_rate=dropout_rate)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
        "grid_result = grid.fit(X, Y)\n",
        "####################################################\n",
        "\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Number of neurons"
      ],
      "metadata": {
        "id": "Jei6X2y2minP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyjTr-3emHKG",
        "outputId": "fb6d0725-b1b5-4e2e-8827-3c7f6ad7f57d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: 0.709635 using {'model__neurons': 10}\n",
            "0.692708 (0.008027) with: {'model__neurons': 1}\n",
            "0.703125 (0.006379) with: {'model__neurons': 5}\n",
            "0.709635 (0.015073) with: {'model__neurons': 10}\n",
            "0.707031 (0.009568) with: {'model__neurons': 15}\n",
            "0.703125 (0.012758) with: {'model__neurons': 20}\n",
            "0.690104 (0.018688) with: {'model__neurons': 25}\n",
            "0.696615 (0.004872) with: {'model__neurons': 30}\n"
          ]
        }
      ],
      "source": [
        "# Use scikit-learn to grid search the number of neurons\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from tensorflow.keras.constraints import MaxNorm\n",
        "\n",
        "# Function to create model, required for KerasClassifier\n",
        "def create_model(neurons):\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(neurons, input_shape=(8,), kernel_initializer='uniform', activation='linear', kernel_constraint=MaxNorm(4)))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\treturn model\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "# load dataset\n",
        "dataset = np.loadtxt(datafile, delimiter=\",\")\n",
        "\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "\n",
        "# create model\n",
        "model = KerasClassifier(model=create_model, epochs=100, batch_size=10, verbose=0)\n",
        "\n",
        "####################################################\n",
        "# define the grid search parameters\n",
        "neurons = [1, 5, 10, 15, 20, 25, 30]\n",
        "param_grid = dict(model__neurons=neurons)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
        "grid_result = grid.fit(X, Y)\n",
        "####################################################\n",
        "\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PajfnwzGmHKH"
      },
      "source": [
        "# Tips for Hyperparameter Optimization\n",
        "This section lists some handy tips to consider when tuning hyperparameters of your neural network.\n",
        "\n",
        "1. k-fold Cross Validation. You can see that the results from the examples in this post show some variance. A default cross-validation of 3 was used, but perhaps k=5 or k=10 would be more stable. Carefully choose your cross validation configuration to ensure your results are stable.\n",
        "2. Review the Whole Grid. Do not just focus on the best result, review the whole grid of results and look for trends to support configuration decisions.\n",
        "3. Parallelize. Use all your cores if you can, neural networks are slow to train and we often want to try a lot of different parameters. Consider spinning up a lot of AWS instances.\n",
        "4. Use a Sample of Your Dataset. Because networks are slow to train, try training them on a smaller sample of your training dataset, just to get an idea of general directions of parameters rather than optimal configurations.\n",
        "5. Start with Coarse Grids. Start with coarse-grained grids and zoom into finer grained grids once you can narrow the scope.\n",
        "6. Do not Transfer Results. Results are generally problem specific. Try to avoid favorite configurations on each new problem that you see. It is unlikely that optimal results you discover on one problem will transfer to your next project. Instead look for broader trends like number of layers or relationships between parameters.\n",
        "7. Reproducibility is a Problem. Although we set the seed for the random number generator in NumPy, the results are not 100% reproducible. There is more to reproducibility when grid searching wrapped Keras models than is presented in this post."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}